{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction using Text Features\n",
    "\n",
    "In miletone 3, we applied SVM and random forest to predict genre from overview and title term frequency, but the test accuracy stuck on about 20%. In milestone 4, we also improved the prediction by modeling the text features from overview of movies. In the following part, we:\n",
    "\n",
    "* Extract features using TF-IDF instead of term frequency from overview, title and tagline\n",
    "* Prescreening the features using chi-square value\n",
    "\n",
    "\n",
    "The new prediction accuracy on the same test set reaches ~46%. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import imdb\n",
    "import numpy                  as np\n",
    "import pandas                 as pd\n",
    "import scipy                  as sp\n",
    "import sklearn.neighbors      as knn\n",
    "import matplotlib\n",
    "import matplotlib.pyplot      as plt\n",
    "import seaborn\n",
    "import requests\n",
    "import urllib\n",
    "import joblib\n",
    "import requests\n",
    "import json\n",
    "import os\n",
    "import random\n",
    "import seaborn as sns\n",
    "#import statsmodels.api as sm\n",
    "from ast                                  import literal_eval\n",
    "from matplotlib                           import rcParams\n",
    "from sklearn                              import discriminant_analysis\n",
    "from sklearn.decomposition                import PCA\n",
    "from sklearn                              import preprocessing\n",
    "from sklearn.linear_model                 import LogisticRegression as LogReg\n",
    "from sklearn.discriminant_analysis        import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.discriminant_analysis        import QuadraticDiscriminantAnalysis as QDA\n",
    "from scipy.stats                          import mode\n",
    "from sklearn                              import linear_model\n",
    "from IPython.core.interactiveshell        import InteractiveShell\n",
    "from time                                 import sleep\n",
    "from collections                          import Counter\n",
    "from itertools                            import combinations, permutations\n",
    "from urlparse                             import urljoin\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.cross_validation import train_test_split as sk_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "matplotlib.style.use('ggplot')\n",
    "rcParams['figure.figsize'] = (20, 10)\n",
    "rcParams['axes.facecolor'] = \"w\"\n",
    "rcParams['grid.color'] = \"gray\"\n",
    "rcParams['grid.linewidth'] = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_first_genre(x):\n",
    "    try:\n",
    "        return [genre['name'] for genre in literal_eval(x)][0]\n",
    "    except Exception:\n",
    "        return 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_mdb_final = pd.read_csv('merged_mdb_final.txt')\n",
    "merged_mdb_final = merged_mdb_final.drop('Unnamed: 0', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merged_mdb_final['genres'].unique()\n",
    "#Pick the first genre randomly to deal with the problem as a multiclass prediction\n",
    "merged_mdb_final['final_genre'] = merged_mdb_final['genres'].map(lambda x: extract_first_genre(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_merged_mdb_final = merged_mdb_final[~merged_mdb_final.final_genre.isin((0,'War', 'Western', \n",
    "                                                                                'TV Movie', 'Foreign',\n",
    "                                                                               'History', 'Music'))].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'Action' u'Adventure' u'Animation' u'Comedy' u'Crime' u'Documentary'\n",
      " u'Drama' u'Family' u'Fantasy' u'Horror' u'Mystery' u'Romance'\n",
      " u'Science Fiction' u'Thriller']\n",
      "4250\n"
     ]
    }
   ],
   "source": [
    "tmp = filtered_merged_mdb_final['final_genre']\n",
    "#print len(tmp[0])\n",
    "#Convert Y variable to numerical value prior to modelling\n",
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "\n",
    "tmp1 = le.fit_transform(tmp)\n",
    "print le.classes_\n",
    "print len(tmp1)\n",
    "yy = pd.DataFrame(tmp1)\n",
    "#merged_mdb_uni2['uni_genre_x'] = le.transform(merged_mdb_uni2['uni_genre_x']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = filtered_merged_mdb_final[['final_genre', 'overview', 'title_x', 'tagline']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([u'title_x', u'imdb_id', u'id', u'overview', u'budget', u'genres',\n",
      "       u'release_date', u'revenue', u'runtime', u'original_language',\n",
      "       u'popularity', u'poster_path', u'production_companies',\n",
      "       u'production_countries', u'spoken_languages', u'tagline',\n",
      "       u'vote_average', u'vote_count', u'title_y', u'rating', u'votes',\n",
      "       u'year', u'cast', u'director', u'writer', u'final_genre'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print filtered_merged_mdb_final.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{u'id': 28, u'name': u'Action'}, {u'id': 878, u'name': u'Science Fiction'}]\n"
     ]
    }
   ],
   "source": [
    "print filtered_merged_mdb_final[['title_x', 'genres', 'tagline']].iloc[4, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract TF-IDF features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('number of words in plot summary: ', 20216)\n"
     ]
    }
   ],
   "source": [
    "## Extract TF-IDF uni-gram from overview\n",
    "vectorizer = TfidfVectorizer(stop_words='english',decode_error='ignore',analyzer='word', min_df=0, max_df=0.9)\n",
    "\n",
    "corpus = filtered_merged_mdb_final['overview'].values.astype('U')\n",
    "\n",
    "wordvec = vectorizer.fit_transform(corpus.ravel())\n",
    "wordvec = wordvec.toarray()\n",
    "words = vectorizer.get_feature_names()\n",
    "print(\"number of words in plot summary: \", len(words))\n",
    "overview_db = pd.DataFrame(wordvec,columns=words)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('number of words in plot summary: ', 4178)\n"
     ]
    }
   ],
   "source": [
    "## Extract TF-IDF uni-gram from title\n",
    "vectorizer = TfidfVectorizer(stop_words='english',decode_error='ignore',analyzer='word', min_df=0, max_df=0.9)\n",
    "\n",
    "corpus = filtered_merged_mdb_final['title_x'].values.astype('U')\n",
    "\n",
    "wordvec = vectorizer.fit_transform(corpus.ravel())\n",
    "wordvec = wordvec.toarray()\n",
    "words = vectorizer.get_feature_names()\n",
    "print(\"number of words in plot summary: \", len(words))\n",
    "title_db = pd.DataFrame(wordvec,columns=words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('number of words in plot summary: ', 3782)\n"
     ]
    }
   ],
   "source": [
    "## Extract TF-IDF uni-gram from overview\n",
    "vectorizer = TfidfVectorizer(stop_words='english',decode_error='ignore',analyzer='word', min_df=0, max_df=0.9)\n",
    "\n",
    "corpus = filtered_merged_mdb_final['tagline'].values.astype('U')\n",
    "\n",
    "wordvec = vectorizer.fit_transform(corpus.ravel())\n",
    "wordvec = wordvec.toarray()\n",
    "words = vectorizer.get_feature_names()\n",
    "print(\"number of words in plot summary: \", len(words))\n",
    "tagline_db = pd.DataFrame(wordvec,columns=words)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prescreening using Chi-square test\n",
    "We find that the prediction performance is best if we only remove the extremely nonclassifiable features, so we filter out those with p-value > 0.999 (this is not a routing statistical test which usually remove the features with p-value < 0.05) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Prescreening the words using chi-square for overview\n",
    "chi2_val, p_val = chi2(X=overview_db.values, y=tmp)\n",
    "xx_overview = overview_db.iloc[:, p_val<=0.997]\n",
    "## Prescreening the words using chi-square for title\n",
    "chi2_val, p_val = chi2(X=title_db.values, y=tmp)\n",
    "xx_title = title_db.iloc[:, p_val<=0.99]\n",
    "## Prescreening the words using chi-square for title\n",
    "chi2_val, p_val = chi2(X=tagline_db.values, y=tmp)\n",
    "xx_tagline = tagline_db.iloc[:, p_val<=0.9]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Build X-Y data for modeling\n",
    "data_overview = pd.merge(yy, xx_overview, left_index=True, right_index=True)\n",
    "data_title = pd.merge(yy, xx_title, left_index=True, right_index=True)\n",
    "data_tagline = pd.merge(yy, xx_tagline, left_index=True, right_index=True)\n",
    "#data2 = pd.merge(data2, zz, left_index=True, right_index=True)\n",
    "data_text = pd.merge(yy, xx_overview, left_index=True, right_index=True)\n",
    "data_text = pd.merge(data_text, xx_title, left_index=True, right_index=True)\n",
    "data_text = pd.merge(data_text, xx_tagline, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling for Overview Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split as sk_split\n",
    "# Split final version of data into training/test data sets\n",
    "data_train, data_test = sk_split(data_overview, test_size = 0.3, random_state=123)\n",
    "trainX = data_train.values[:, 1:]\n",
    "trainY = data_train.values[:, 0]\n",
    "testX = data_test.values[:, 1:]\n",
    "testY = data_test.values[:, 0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=10, class_weight='balanced', dual=False,\n",
       "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "          multi_class='ovr', n_jobs=1, penalty='l2', random_state=10,\n",
       "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy:\t0.906554621849\n",
      "Test accuracy:\t\t0.456470588235\n"
     ]
    }
   ],
   "source": [
    "model_logistic = LogReg(random_state=10, C=10, class_weight='balanced')\n",
    "model_logistic.fit(X=trainX, y=trainY)\n",
    "print 'Training accuracy:\\t', model_logistic.score(X=trainX, y=trainY)\n",
    "print 'Test accuracy:\\t\\t', model_logistic.score(X=testX, y=testY)\n",
    "trainY_pred = model_logistic.predict_proba(X=trainX)\n",
    "testY_pred = model_logistic.predict_proba(X=testX)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We can see the test accuracy using simple logistic regression can reach 45.6%. The confusion matrix is shown below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Action</th>\n",
       "      <th>Adventure</th>\n",
       "      <th>Animation</th>\n",
       "      <th>Comedy</th>\n",
       "      <th>Crime</th>\n",
       "      <th>Documentary</th>\n",
       "      <th>Drama</th>\n",
       "      <th>Family</th>\n",
       "      <th>Fantasy</th>\n",
       "      <th>Horror</th>\n",
       "      <th>Mystery</th>\n",
       "      <th>Romance</th>\n",
       "      <th>Science Fiction</th>\n",
       "      <th>Thriller</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Action</th>\n",
       "      <td>123</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>35</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>53</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Adventure</th>\n",
       "      <td>17</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Animation</th>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Comedy</th>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>153</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>58</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Crime</th>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Documentary</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Drama</th>\n",
       "      <td>26</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>78</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>175</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Family</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fantasy</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Horror</th>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mystery</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Romance</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Science Fiction</th>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Thriller</th>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Action  Adventure  Animation  Comedy  Crime  Documentary  \\\n",
       "Action              123          3          3      35      3            0   \n",
       "Adventure            17         13          3      18      0            1   \n",
       "Animation            13          2          6      17      0            2   \n",
       "Comedy               26          1          1     153      0            0   \n",
       "Crime                13          1          0      12      4            0   \n",
       "Documentary           3          2          0       8      0            6   \n",
       "Drama                26          3          0      78      1            0   \n",
       "Family                5          2          2       8      0            0   \n",
       "Fantasy               2          2          0      14      0            0   \n",
       "Horror               11          4          0      17      0            0   \n",
       "Mystery               4          0          0       3      0            0   \n",
       "Romance               0          0          0      16      0            0   \n",
       "Science Fiction      11          1          0       4      0            1   \n",
       "Thriller             10          2          0      11      2            0   \n",
       "\n",
       "                 Drama  Family  Fantasy  Horror  Mystery  Romance  \\\n",
       "Action              53       0        0       5        0        0   \n",
       "Adventure           16       1        0       3        0        0   \n",
       "Animation            8       2        0       2        0        0   \n",
       "Comedy              58       2        0       7        0        1   \n",
       "Crime               24       0        0       3        2        0   \n",
       "Documentary         14       0        0       0        0        0   \n",
       "Drama              175       0        0      12        1        1   \n",
       "Family               6       0        0       3        0        0   \n",
       "Fantasy             10       0        3       1        0        0   \n",
       "Horror              24       0        0      34        1        0   \n",
       "Mystery              7       0        0       2        0        0   \n",
       "Romance              8       0        0       0        0        0   \n",
       "Science Fiction      4       0        0       3        0        0   \n",
       "Thriller            24       0        0      12        0        0   \n",
       "\n",
       "                 Science Fiction  Thriller  \n",
       "Action                         0         0  \n",
       "Adventure                      0         1  \n",
       "Animation                      0         0  \n",
       "Comedy                         0         0  \n",
       "Crime                          0         5  \n",
       "Documentary                    0         0  \n",
       "Drama                          0         1  \n",
       "Family                         0         0  \n",
       "Fantasy                        1         0  \n",
       "Horror                         0         3  \n",
       "Mystery                        0         0  \n",
       "Romance                        0         0  \n",
       "Science Fiction                1         0  \n",
       "Thriller                       1         1  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Compute confusion matrix\n",
    "testY_hat = model_logistic.predict(X=testX)\n",
    "pd.DataFrame(data=confusion_matrix(y_true=testY, y_pred=testY_hat), index=le.classes_, columns=le.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1, class_weight='balanced', dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=10, tol=0.0001,\n",
       "     verbose=0)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.91764705882352937"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.42980392156862746"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_lsvm = LinearSVC(random_state=10, C=1,class_weight='balanced')\n",
    "model_lsvm.fit(X=trainX, y=trainY)\n",
    "model_lsvm.score(X=trainX, y=trainY)\n",
    "model_lsvm.score(X=testX, y=testY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We also tried linear SVM but the test accuracy is slight lower than logistic regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=20,\n",
       "            max_features='auto', max_leaf_nodes=None, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            presort=False, random_state=None, splitter='best')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy:\t0.345546218487\n",
      "Test accuracy:\t\t0.256470588235\n"
     ]
    }
   ],
   "source": [
    "dt_stump = DecisionTreeClassifier(max_depth=20, max_features='auto')\n",
    "dt_stump.fit(X=trainX, y=trainY)\n",
    "print 'Training accuracy:\\t', dt_stump.score(X=trainX, y=trainY)\n",
    "print 'Test accuracy:\\t\\t', dt_stump.score(X=testX, y=testY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(algorithm='SAMME.R',\n",
       "          base_estimator=DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=20,\n",
       "            max_features='auto', max_leaf_nodes=None, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            presort=False, random_state=None, splitter='best'),\n",
       "          learning_rate=1.0, n_estimators=100, random_state=10)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy:\t0.746554621849\n",
      "Test accuracy:\t\t0.276078431373\n"
     ]
    }
   ],
   "source": [
    "model_adaboost = AdaBoostClassifier(base_estimator=dt_stump, n_estimators=100, random_state=10)\n",
    "model_adaboost.fit(X=trainX, y=trainY)\n",
    "print 'Training accuracy:\\t', model_adaboost.score(X=trainX, y=trainY)\n",
    "print 'Test accuracy:\\t\\t', model_adaboost.score(X=testX, y=testY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The performance of decision tree and adaboost is disappointing in this problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble with Deep Learning on Poster Images\n",
    "We combine the results from overview text and the results from deep learning for poster images. The final test accuracy is 47.4%. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of ensemble:  0.472156862745\n"
     ]
    }
   ],
   "source": [
    "train_pred_poster = pd.read_csv('train_pred.csv')\n",
    "test_pred_poster = pd.read_csv('test_pred.csv')\n",
    "#testYY = np.concatenate((testY_pred, test_pred_poster.values), axis=1)\n",
    "alpha = 0.76\n",
    "testYY2 = alpha*testY_pred + (1-alpha) * test_pred_poster.values\n",
    "testY_pred1 = np.argmax(testYY2, axis=1)\n",
    "print 'Accuracy of ensemble: ', np.mean(testY_pred1 == testY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling for Title Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split as sk_split\n",
    "# Split final version of data into training/test data sets\n",
    "data_train, data_test = sk_split(data_title, test_size = 0.3, random_state=123)\n",
    "trainX = data_train.values[:, 1:]\n",
    "trainY = data_train.values[:, 0]\n",
    "testX = data_test.values[:, 1:]\n",
    "testY = data_test.values[:, 0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.1, class_weight='balanced', dual=False,\n",
       "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "          multi_class='ovr', n_jobs=1, penalty='l2', random_state=10,\n",
       "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy:\t0.426890756303\n",
      "Test accuracy:\t\t0.276078431373\n"
     ]
    }
   ],
   "source": [
    "model_logistic = LogReg(random_state=10, C=0.1,class_weight='balanced')\n",
    "model_logistic.fit(X=trainX, y=trainY)\n",
    "print 'Training accuracy:\\t', model_logistic.score(X=trainX, y=trainY)\n",
    "print 'Test accuracy:\\t\\t', model_logistic.score(X=testX, y=testY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling for Tagline Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4250, 1231)\n"
     ]
    }
   ],
   "source": [
    "## Prescreening the words using chi-square for title\n",
    "chi2_val, p_val = chi2(X=tagline_db.values, y=tmp)\n",
    "xx_tagline = tagline_db.iloc[:, p_val<=0.9]\n",
    "print xx_tagline.shape\n",
    "data_tagline = pd.merge(yy, xx_tagline, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.cross_validation import train_test_split as sk_split\n",
    "# Split final version of data into training/test data sets\n",
    "data_train, data_test = sk_split(data_tagline, test_size = 0.3, random_state=123)\n",
    "trainX = data_train.values[:, 1:]\n",
    "trainY = data_train.values[:, 0]\n",
    "testX = data_test.values[:, 1:]\n",
    "testY = data_test.values[:, 0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=10, class_weight='balanced', dual=False,\n",
       "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "          multi_class='ovr', n_jobs=1, penalty='l2', random_state=10,\n",
       "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy:\t0.522352941176\n",
      "Test accuracy:\t\t0.233725490196\n"
     ]
    }
   ],
   "source": [
    "model_logistic = LogReg(random_state=10, C=10, class_weight='balanced')\n",
    "model_logistic.fit(X=trainX, y=trainY)\n",
    "print 'Training accuracy:\\t', model_logistic.score(X=trainX, y=trainY)\n",
    "print 'Test accuracy:\\t\\t', model_logistic.score(X=testX, y=testY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see the prediction accuracy using tapline data is only about 23%. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling using Text Data from Overview, Title and Tagline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.cross_validation import train_test_split as sk_split\n",
    "# Split final version of data into training/test data sets\n",
    "data_train, data_test = sk_split(data_text, test_size = 0.3, random_state=123)\n",
    "trainX = data_train.values[:, 1:]\n",
    "trainY = data_train.values[:, 0]\n",
    "testX = data_test.values[:, 1:]\n",
    "testY = data_test.values[:, 0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=10, class_weight='balanced', dual=False,\n",
       "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "          multi_class='ovr', n_jobs=1, penalty='l2', random_state=10,\n",
       "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy:\t0.97512605042\n",
      "Test accuracy:\t\t0.439215686275\n"
     ]
    }
   ],
   "source": [
    "model_logistic = LogReg(random_state=10, C=10, class_weight='balanced')\n",
    "model_logistic.fit(X=trainX, y=trainY)\n",
    "print 'Training accuracy:\\t', model_logistic.score(X=trainX, y=trainY)\n",
    "print 'Test accuracy:\\t\\t', model_logistic.score(X=testX, y=testY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see the performance using Overview, Title and Tagline features can not reach the performance using overview feature only. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In the following part, we tried to use both uni-gram and bi-gram for prediction. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('number of words in plot summary: ', 124081)\n",
      "53622\n"
     ]
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer(stop_words='english',decode_error='ignore',analyzer='word', min_df=0, max_df=0.9, ngram_range=(1,2))\n",
    "corpus1 = data1['overview'].values.astype('U')\n",
    "wordvec1 = tfidf.fit_transform(corpus1.ravel())\n",
    "wordvec1 = wordvec1.toarray()\n",
    "words1 = tfidf.get_feature_names()\n",
    "print(\"number of words in plot summary: \", len(words1))\n",
    "overview_db1 = pd.DataFrame(wordvec1,columns=words1)\n",
    "\n",
    "chi2_val, p_val = chi2(X=overview_db1.values, y=tmp)\n",
    "xx = overview_db1.iloc[:, p_val<=1-1e-5]\n",
    "#xx = overview_db1\n",
    "data_bigram = pd.merge(yy, xx, left_index=True, right_index=True)\n",
    "print len(data_bigram.columns)\n",
    "\n",
    "data_train1, data_test1 = sk_split(data_bigram, test_size = 0.3, random_state=123)\n",
    "trainX1 = data_train1.values[:, 1:]\n",
    "trainY1 = data_train1.values[:, 0]\n",
    "testX1 = data_test1.values[:, 1:]\n",
    "testY1 = data_test1.values[:, 0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=10, class_weight='balanced', dual=False,\n",
       "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "          multi_class='ovr', n_jobs=1, penalty='l2', random_state=10,\n",
       "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.96773109243697475"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.41254901960784313"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_logistic1 = LogReg(random_state=10, C=10,class_weight='balanced')\n",
    "model_logistic1.fit(X=trainX1, y=trainY1)\n",
    "model_logistic1.score(X=trainX1, y=trainY1)\n",
    "model_logistic1.score(X=testX1, y=testY1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We notice that the prediction accuracy using bi-gram is not as good as that using uni-gram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
